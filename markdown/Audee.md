---
Title: "Audee"
Tags: ["2020", "ASE", "DL framework", "Read", "differential fuzzing", "fuzzing", "numerical"]
Authors: ['Guo', 'Qianyu', 'Xie', 'Xiaofei', 'Li', 'Yi', 'Zhang', 'Xiaoyu', 'Liu', 'Yang', 'Li', 'Xiaohong', 'Shen', 'Chao']
Collections: ["patch detection â–¸ DL"]
Conference: ASE
Date Added: October 26, 2023 10:41 AM (UTC)
Short Title: Audee
Full Title: "Audee: Automated Testing for Deep Learning Frameworks"
URL: https://ieeexplore.ieee.org/document/9286000
Year: 2020
code: https://sites.google.com/view/audee
---
# Audee: automated testing for deep learning frameworks

code: [https://sites.google.com/view/audee](https://sites.google.com/view/audee)

AudeeåŸºäºæœç´¢å®ç°äº†ç»“åˆæ¨¡å‹structuresã€å‚æ•°ã€æƒé‡ä»¥åŠè¾“å…¥çš„ä¸‰ç§ä¸åŒçš„çš„å˜å¼‚ç­–ç•¥ï¼Œå¯ä»¥æ£€æµ‹logic error, crashes and NaN errors.

å¯¹äºlogic errorï¼ŒAudeeé‡‡ç”¨cross-reference checkæ¥æ£€æµ‹å¤šä¸ªframeworkä¹‹é—´çš„è¡Œä¸ºä¸ä¸€è‡´ã€‚å¯¹äºNaN errorï¼ŒAudeeé‡‡ç”¨åŸºäºå¯å‘å¼çš„æ–¹æ³•æ¥ç”Ÿæˆå€¾å‘äºè¾“å‡ºå¼‚å¸¸å€¼ï¼ˆè¿‡å¤§æˆ–è¿‡å°ï¼‰çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰ã€‚æ­¤åï¼ŒAudeeåˆ©ç”¨åŸºäºå› æœæµ‹è¯•çš„æŠ€æœ¯æ¥å®šä½å¯¼è‡´ä¸ä¸€è‡´æˆ–é”™è¯¯çš„å±‚å’Œå‚æ•°ã€‚

é€šè¿‡åœ¨4ä¸ªDL frameworkï¼ˆTensorFlow, PyTorch, CNTK, and Theanoï¼‰ä¸Šå¯¹Audeeè¿›è¡Œæµ‹è¯•ï¼ŒAudeeç”Ÿæˆäº†æ¶µç›–4ä¸ªDL frameworkä¸­25ä¸ªAPIçš„å¤§é‡æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰ã€‚æœ€ç»ˆå‘ç°äº†26ä¸ªç‹¬ç‰¹çš„bugsï¼Œå…¶ä¸­7ä¸ªå·²ç»è¢«å¼€å‘è€…ç¡®è®¤æˆ–ä¿®å¤ã€‚

## Introduction

æ·±åº¦å­¦ä¹ ç³»ç»Ÿé€šå¸¸åŒ…æ‹¬3ä¸ªå±‚æ¬¡ï¼šthe application (e.g., DNN design), the DL framework (e.g., basic DL functionality support) and the hardware support (e.g., CUDA, CPU, and GPU). å¼€å‘è€…é¦–å…ˆæ”¶é›†è®­ç»ƒæ•°æ®å¹¶ä½¿ç”¨DL frameworksæä¾›çš„APIè®¾è®¡æ·±åº¦å­¦ä¹ ç½‘ç»œï¼ˆDNNsï¼‰ï¼Œæ­¤åDNNåœ¨framworksåŠç¡¬ä»¶æ”¯æŒçš„åŸºç¡€ä¸Šè®­ç»ƒå¹¶æ¨ç†ã€‚

### Challenges

ï¼ˆ1ï¼‰DL testing

1ï¼‰test case. DL frameworkçš„test caseåŒ…æ‹¬æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰ä»¥åŠè¾“å…¥ï¼Œä½¿ç”¨ç°æœ‰çš„æ·±åº¦ç¥ç»ç½‘ç»œæ•°æ®é›†æ— æ³•cover all framework behaviours and may miss some bugsã€‚

2ï¼‰ç¼ºå°‘å¯¹äºlogical bugsçš„oracleã€‚è™½ç„¶ä½¿ç”¨differential testingå¯ä»¥é€šè¿‡æ£€æµ‹ä¸åŒframworkçš„ä¸ä¸€è‡´æ€§å‘ç°logical bugsï¼Œä½†æ— æ³•ç¡®å®šå…¶æ ¹æœ¬åŸå› ã€‚

ï¼ˆ2ï¼‰fault localization

1ï¼‰DNNå±‚æ•°ã€å‚æ•°ä¼—å¤šï¼Œéš¾ä»¥ç¡®å®šæ˜¯å“ªä¸€å±‚ã€å“ªä¸ªå‚æ•°å¯¼è‡´çš„inconsistencyã€‚

2ï¼‰æœ‰é—®é¢˜çš„layerå¯èƒ½ä¼šå½±å“æ²¡æœ‰é—®é¢˜çš„subsequent layersã€‚ï¼ˆCRADLEä½¿ç”¨metricå»æ£€æµ‹inconsistency degreeæ¥è¿›è¡Œbuggy layer localizationï¼Œä½†ç¡®å®šdegreeå¾ˆå›°éš¾ã€‚ï¼‰

â†’å¯¹äºæ¯å±‚è¿›è¡Œ

<img src="/Audee/Untitled.png" className="img"/>
## Approach

<img src="/Audee/Untitled%201.png" className="img"/>
ï¼ˆ1ï¼‰å˜å¼‚ç­–ç•¥

- Network-level. å˜å¼‚DNNæ¯å±‚å‚æ•°
- Input-level. å˜å¼‚DNNçš„è¾“å…¥
- Weight-level. å˜å¼‚DNNçš„æƒé‡

### Search-based DL Framework Testing

ç”±äºinputs&weightsçš„é«˜ç»´ç‰¹æ€§ï¼Œæ‰€ä»¥å¾ˆéš¾éå†æ‰€æœ‰çš„casesã€‚â†’å¦‚ä½•é€‰æ‹©æœ€å¯èƒ½è§¦å‘å¼‚å¸¸çš„æœ€ä¼˜inputs&weightsâ†’åŸºäºGenetic Algorithmçš„å˜å¼‚ç­–ç•¥

### Inconsistency

- layer distance

### NaN

- ä½œè€…é€šè¿‡é€å±‚è¿½è¸ªNaN casesï¼Œå‘ç°NaNé—®é¢˜é€šå¸¸æ˜¯ç”±äºoutlier valueså¼•èµ·ï¼Œç‰¹åˆ«æ˜¯å½“è®¡ç®—ä¸­åŒ…å«ç‰¹åˆ«å¤§æˆ–ç‰¹åˆ«å°çš„å€¼ã€‚
- NaN fitness function
    - è¾“å‡ºå‘é‡çš„æœ€å¤§å€¼ä¸æœ€å°å€¼ä¹‹å·®
        
<img src="/Audee/Untitled%202.png" className="img"/>        
    - ä½¿ç”¨NaN fitness functionè¡¨å¾æŸå±‚æ•°æ®åˆ†å¸ƒä¸å¹³è¡¡ç¨‹åº¦ï¼ˆè¶Šä¸å¹³è¡¡çš„æ•°æ®è¶Šå¯èƒ½è§¦å‘NaN bugsï¼‰
        - ä½œè€…é€šè¿‡é€å±‚è¿½è¸ªNaN casesï¼Œå‘ç°NaNé—®é¢˜é€šå¸¸æ˜¯ç”±äºoutlier valueså¼•èµ·ï¼Œç‰¹åˆ«æ˜¯å½“è®¡ç®—ä¸­åŒ…å«ç‰¹åˆ«å¤§æˆ–ç‰¹åˆ«å°çš„å€¼ã€‚
            
            > In TensorFlow, it is implemented as ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥ (ğ‘¥) = ğ‘¡ğ‘“.ğ‘’ğ‘¥ğ‘(ğ‘¥)/ğ‘¡ğ‘“.ğ‘Ÿğ‘’ğ‘‘ğ‘¢ğ‘ğ‘’_ğ‘ ğ‘¢ğ‘š(ğ‘¡ğ‘“.ğ‘’ğ‘¥ğ‘(ğ‘¥)), where ğ‘¥ is a numerical vector. If there is an element that is too large in ğ‘¥, ğ‘¡ğ‘“.ğ‘’ğ‘¥ğ‘ may output an inf value, which can further lead to NaN when the inf involves in some arithmetics [[43]](https://github.com/uTensor/uTensor/issues/175). Another example is the square root operation which is also common in the implementation of the DL framework. It generates a NaN output if the input contains negative elements (see the NaN bug [[47]](https://github.com/tensorflow/tensorflow/issues/38644)). Both cases can be attributed to the unbalanced numerical distribution when the inputs or weights participate in calculation.
            > 
    - é€šè¿‡è¯„ä¼°æ¯ä¸€å±‚çš„è¾“å‡ºï¼Œä»¥è¯†åˆ«é‚£äº›å¯èƒ½ä¼šåœ¨ç»è¿‡åç»­å±‚çš„è®¡ç®—åå¯¼è‡´æ•°å€¼ä¸ç¨³å®šæ€§çš„æç«¯å€¼ã€‚
- select the logits layer to calculate the NaN fitness

### Oracles

(1) Crashes. ç›‘æµ‹DNNè½½å…¥å’Œæ¨ç†çš„è¿‡ç¨‹ä¸­æœ‰æ²¡æœ‰å¼‚å¸¸é€€å‡º

(2) NaN errors. æ¯å±‚ä¸­æœ‰æ²¡æœ‰NaNè¾“å‡º

(3) Logical bugs. æ·±åº¦å­¦ä¹ æ¡†æ¶ä¹‹é—´cross-checkingæ£€æŸ¥ä¸ä¸€è‡´æ€§

### Fault localization

CRADLEæ ¹æ®change rateç¡®å®šfault localizationä¼šé€ æˆFPï¼Œå› ä¸ºæ­£ç¡®çš„layerä¹Ÿå¯èƒ½æœ‰high change rateã€‚

Audeeè¿›è¡Œç»†ç²’åº¦çš„localize-fixç­–ç•¥ï¼Œè‡ªé¡¶å‘ä¸‹é€å±‚åˆ†æchange rateï¼Œå¦‚æœchange rateè¿‡é«˜å°±å°è¯•ä¿®å¤è¿™å±‚çš„é—®é¢˜ã€‚

### NaN bugs

- **[BatchNormalization](https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F38644&sa=D&sntz=1&usg=AOvVaw3UOCiWxaqkhGNlbfPpEMPA)** on **TensorFlow and Theano** ***Confirmed***

When executing ***BatchNormalization***, TensorFlow and Theano return NaN in some cases. This is because both two frameworks lack neceessary check for negative values before calculating square root operations in ***BatchNormalization.***

TensorFlow has confirmed this bug, and the relevant source code for Theano is shown in the following picture.

[https://lh6.googleusercontent.com/y4ru56jhlCemZJDXLSDn76-IQF0Omh5foxBJ-xh7PnDGh6ZV49RvbOjFoGtSZ5U4cVtBvO5xBIZursIq30lSt--F2G8XTXJrvyD6QWZWGfX5Bftu=w1280](https://lh6.googleusercontent.com/y4ru56jhlCemZJDXLSDn76-IQF0Omh5foxBJ-xh7PnDGh6ZV49RvbOjFoGtSZ5U4cVtBvO5xBIZursIq30lSt--F2G8XTXJrvyD6QWZWGfX5Bftu=w1280)

- **[ReLU](https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F38640&sa=D&sntz=1&usg=AOvVaw1TVDk-IKQI0RLvA5HdMKDm)***(threshold=None) on TensorFlow* ***[Confirmed and Fixed](https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2F3db8df8ffafe5bcd83a12b92bc4c8287cd80237f&sa=D&sntz=1&usg=AOvVaw2Ca5ulGvbFzzhHb-_wROjv)***

TensorFlow lacks necessary exception check for floating-point parameters. In case of abnormal values like None, it directly convert them to NaN, which affects the subsequent calculation.  TensorFlow has confirmed and fixed this issue as follows.

[https://lh4.googleusercontent.com/kOysWpW9hsf8aXGez5Qz1YKjXXhz8kT3sf8c1Thqf1nNo_lUQhCp5d5bThhfXDTrsXU8mYXkRRqgd2WWN0QJa5Fxz658UXWZSOm7t4duDUGBuCF1=w1280](https://lh4.googleusercontent.com/kOysWpW9hsf8aXGez5Qz1YKjXXhz8kT3sf8c1Thqf1nNo_lUQhCp5d5bThhfXDTrsXU8mYXkRRqgd2WWN0QJa5Fxz658UXWZSOm7t4duDUGBuCF1=w1280)

- **[LeakyReLU](https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fkeras-team%2Fkeras%2Fissues%2F13787&sa=D&sntz=1&usg=AOvVaw358U9nbBP9O7gePqcgFqS8)***(alpha=None)* on TensorFlow ***Confirmed***

Similar to the **ReLU** bug mentioned above. That is, TensorFlow directly converts the ***None***-value to NaN for the floating-point parameter ***alpha*** in **LeakyReLU**.

- **[AvgPool2d](https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fpytorch%2Fpytorch%2Fissues%2F36977&sa=D&sntz=1&usg=AOvVaw2FsMrQ09TEY9A4zndI_0o-)** on PyTorch ***Confirmed***

Under ***ceil_mode=True*** for ***AvgPool2d***, PyTorch may choose the pools out of the image in some cases and further lead to division-by-zero, which finally triggers NaN output.

- **Dense/Conv/LSTM/GRU/SimpleRNN** on **Tensorflow**, **CNTK**, and **Theano**

Using **exponential** activation in some APIs (e.g., **Conv2D, Dense**) can easily lead to infinity output and trigger NaN when using the infinity value in further calculations. Figure1 shows a NaN example caused by the layer ***SimpleRNN*** with the parameter ***activation=exp*** on TensorFlow.

[https://lh5.googleusercontent.com/CIvkWrIYvI417njf4eEdoueK27zqU5lh7akvMIK_-cjl7N-gP8j5IHRC_kPllW_DMLHQysdTO8rQJIVRKMKZu-22gzNzH9tn4aKk45dlaFhuQFMX=w1280](https://lh5.googleusercontent.com/CIvkWrIYvI417njf4eEdoueK27zqU5lh7akvMIK_-cjl7N-gP8j5IHRC_kPllW_DMLHQysdTO8rQJIVRKMKZu-22gzNzH9tn4aKk45dlaFhuQFMX=w1280)

Figure 1. NaN example on ***SimpleRNN*** with the parameter ***activation=exp*** on TensorFlow

[https://lh3.googleusercontent.com/5EluQ4dkzDmfC-Bg61VHbShFyQPWnoe58t1ygjp5ihshDEF2zUMsDTz8NpCLl1dzrfdMyN7URLgq84N5Mw45ZgFxPg0M63uKiSreBX0LZDP1_V7-=w1280](https://lh3.googleusercontent.com/5EluQ4dkzDmfC-Bg61VHbShFyQPWnoe58t1ygjp5ihshDEF2zUMsDTz8NpCLl1dzrfdMyN7URLgq84N5Mw45ZgFxPg0M63uKiSreBX0LZDP1_V7-=w1280)

Figure 2.   Keras implementation of ***dilation_rate*** for **SeprableConv2D/DepthwiseConv2D** on CNTK backend

### confirmed or fixed bugs

- CNTK. 2020. CNTK has supporting issues with GRU(unroll=true). [https://github.com/microsoft/CNTK/issues/3800](https://github.com/microsoft/CNTK/issues/3800)
- Keras. 2020. Keras has supporting issues with GRU (unroll=true) on the CNTK backend. [https://github.com/keras-team/keras/issues/13852](https://github.com/keras-team/keras/issues/13852)
- Pytorch. 2020. AvgPool: Ensure all cells are valid in ceil mode. [https://github.com/pytorch/pytorch/pull/41368](https://github.com/pytorch/pytorch/pull/41368)
- TensorFlow. 2020. Checking if Kernel_size=0 in conv2d and reports error accordingly. [https://github.com/tensorflow/tensorflow/pull/37395](https://github.com/tensorflow/tensorflow/pull/37395)
- TensorFlow. 2020. The fix of corner cases for the value None processing. [https://github.com/tensorflow/tensorflow/commit/3db8df8ffafe5bcd83a12b92bc4c8287cd80237f](https://github.com/tensorflow/tensorflow/commit/3db8df8ffafe5bcd83a12b92bc4c8287cd80237f)
- TensorFlow. 2020. The fix of missing check for the unreasonable parameter input_dim=0 in the layer Embedding. [https://github.com/tensorflow/tensorflow/commit/f61175812426009a4c96e51befb2951612990903](https://github.com/tensorflow/tensorflow/commit/f61175812426009a4c96e51befb2951612990903)
- TensorFlow. 2020. The output of BatchNormalization may contain Nan under certain parameters. [https://github.com/tensorflow/tensorflow/issues/38644](https://github.com/tensorflow/tensorflow/issues/38644)
- TensorFlow. 2020. Tensorflow can build and even run a model with Conv2D kerne_size=0. [https://github.com/tensorflow/tensorflow/issues/37334](https://github.com/tensorflow/tensorflow/issues/37334)
- Theano. 2020. Theano lacks a check for unreasonable parameters like dilation_rate=0 in Conv2D or DepthwiseConv2D. [https://github.com/Theano/Theano/issues/6745](https://github.com/Theano/Theano/issues/6745)

### All 26 bugs

[https://sites.google.com/view/audee](https://sites.google.com/view/audee)

## Related Work

- An empirical study towards characterizing deep learning development and deployment across different frameworks and platforms. ASE 2019.
- An empirical study on TensorFlow program bugs. ISSTA 2018.
- Taxonomy of Real Faults in Deep Learning Systems. arxiv 2019.
- Tensorfuzz: Debugging neural networks with coverage-guided fuzzing. arxiv 2018.

---

- å¦‚ä½•æ£€æµ‹logical bugsï¼Ÿ
    - é€šè¿‡differential fuzzing
- å¦‚ä½•æ£€æµ‹NaN errorï¼Ÿ
    - TensorFuzz: é€šè¿‡ç”Ÿæˆâ€surprisingâ€ input dataè§¦å‘NaN bugs
    - Audee: åŸºäºæœç´¢ç”Ÿæˆunbalanced distributed valuesï¼ˆåˆ†å¸ƒä¸å¹³è¡¡çš„å€¼ï¼‰
- å¯¼è‡´logical bugs/NaN errorçš„root causeéƒ½æ˜¯ä»€ä¹ˆï¼Ÿ
    - corner cases handling. e.g., TensorFlowå’ŒTheanoåœ¨BatchNormalizationä¸­ä½¿ç”¨sqrtæ—¶æ²¡æœ‰ä¿è¯æ‰€æœ‰è¾“å…¥éƒ½positiveï¼Œé€ æˆNaN bugã€‚
    - logical implementation. e.g., Pytorchä»…åœ¨è®¾ç½®äº†å¡«å……é€‰é¡¹æ—¶æ‰è¿›è¡Œï¼ˆæ± åŒ–å•å…ƒåœ¨å›¾åƒæŸä¸€ç»´åº¦ä¸Šæ˜¯ä»å›¾åƒå†…éƒ¨å¼€å§‹çš„ï¼‰æ¡ä»¶æ£€æŸ¥ï¼Œä½†åœ¨æ²¡æœ‰è®¾ç½®å¡«å……é€‰é¡¹æ—¶ä¹Ÿå¯èƒ½å‡ºç°æ± åŒ–å•å…ƒè¶…å‡ºå›¾åƒè¾¹ç•Œçš„é—®é¢˜ï¼Œé€ æˆNaN bugã€‚
    - overflow/underflow
- Audeeæ£€æµ‹NaN errorçš„ç¼ºé™·åœ¨äºä»€ä¹ˆï¼Ÿé€šè¿‡è¿™ç§åŸºäºæœç´¢ç”Ÿæˆunbalanced distributed valuesæœ‰ä»€ä¹ˆç¼ºç‚¹ï¼Ÿ
    - ç”ŸæˆDNNæ¨¡å‹+å‚æ•°ï¼ˆinput+weightï¼‰ï¼Œè¦†ç›–ç‡é—®é¢˜ã€‚ã€é™æ€åˆ†æå¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜å—ï¼Ÿã€‘
    - NaNé—®é¢˜ä¸€å®šæ˜¯unbalanced distributed valueså¯ä»¥è§¦å‘çš„å—ï¼Ÿ
- Audee search-basedå’Œheuristic-basedæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ
- â€œNote that, neither of TensorFuzz and Audee can detect NaNs on some DNNs (e.g., the RNN models) and frameworks (e.g., PyTorch), thus we ignore them in Table 3.â€ (Guo et al., 2021, p. 494) (pdf)